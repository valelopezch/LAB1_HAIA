{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm_annealing import CatanGA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 - Best Individual: [0.0248, 0.1568, 0.0999, 0.1139, 0.0683, 0.3308, 0.1062, 0.0325, 0.0505, 0.0163], Max Fitness: 0.7250, Avg Fitness: 0.4394\n",
      "Generation 1 - Best Individual: [0.0024, 0.1709, 0.294, 0.3624, 0.0286, 0.0369, 0.0847, 0.014, 0.0053, 0.0008], Max Fitness: 0.6825, Avg Fitness: 0.4782\n",
      "Generation 2 - Best Individual: [0.0033, 0.0151, 0.0671, 0.0671, 0.0406, 0.6043, 0.1025, 0.0406, 0.0239, 0.0355], Max Fitness: 0.6750, Avg Fitness: 0.5077\n",
      "Generation 3 - Best Individual: [0.0033, 0.0151, 0.0671, 0.0671, 0.0406, 0.6043, 0.1025, 0.0406, 0.0239, 0.0355], Max Fitness: 0.6750, Avg Fitness: 0.5239\n",
      "Generation 4 - Best Individual: [0.0103, 0.0224, 0.006, 0.0213, 0.3951, 0.0505, 0.2229, 0.0218, 0.2095, 0.0403], Max Fitness: 0.6750, Avg Fitness: 0.5318\n",
      "Generation 5 - Best Individual: [0.0103, 0.0224, 0.006, 0.0213, 0.3951, 0.0505, 0.2229, 0.0218, 0.2095, 0.0403], Max Fitness: 0.6750, Avg Fitness: 0.5645\n",
      "Generation 6 - Best Individual: [0.0103, 0.0224, 0.006, 0.0213, 0.3951, 0.0505, 0.2229, 0.0218, 0.2095, 0.0403], Max Fitness: 0.6750, Avg Fitness: 0.5683\n",
      "Generation 7 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1849, 0.0474], Max Fitness: 0.7000, Avg Fitness: 0.5763\n",
      "Generation 8 - Best Individual: [0.0082, 0.0228, 0.0155, 0.0464, 0.2594, 0.4131, 0.0228, 0.0264, 0.139, 0.0464], Max Fitness: 0.7025, Avg Fitness: 0.5636\n",
      "Generation 9 - Best Individual: [0.0101, 0.0248, 0.0117, 0.0475, 0.3596, 0.2545, 0.0265, 0.0265, 0.1913, 0.0475], Max Fitness: 0.7125, Avg Fitness: 0.6029\n",
      "Generation 10 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7175, Avg Fitness: 0.5915\n",
      "Generation 11 - Best Individual: [0.01, 0.1881, 0.012, 0.0474, 0.3534, 0.2649, 0.0256, 0.0265, 0.0247, 0.0474], Max Fitness: 0.7275, Avg Fitness: 0.6038\n",
      "Generation 12 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0264, 0.3465, 0.2748, 0.0473, 0.0264, 0.1845, 0.0473], Max Fitness: 0.7150, Avg Fitness: 0.6027\n",
      "Generation 13 - Best Individual: [0.0099, 0.0887, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1208, 0.0474], Max Fitness: 0.7200, Avg Fitness: 0.6061\n",
      "Generation 14 - Best Individual: [0.01, 0.1881, 0.012, 0.0474, 0.3534, 0.2649, 0.0256, 0.0265, 0.0247, 0.0474], Max Fitness: 0.7275, Avg Fitness: 0.6072\n",
      "Generation 15 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7175, Avg Fitness: 0.6155\n",
      "Generation 16 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1849, 0.0474], Max Fitness: 0.6750, Avg Fitness: 0.6076\n",
      "Generation 17 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1849, 0.0474], Max Fitness: 0.7000, Avg Fitness: 0.6044\n",
      "Generation 18 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7025, Avg Fitness: 0.6167\n",
      "Generation 19 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7175, Avg Fitness: 0.6128\n",
      "Generation 20 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7025, Avg Fitness: 0.5981\n",
      "Generation 21 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1849, 0.0474], Max Fitness: 0.7000, Avg Fitness: 0.6098\n",
      "Generation 22 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.1849, 0.0474], Max Fitness: 0.7000, Avg Fitness: 0.6016\n",
      "Generation 23 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7175, Avg Fitness: 0.6059\n",
      "Generation 24 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6091\n",
      "Generation 25 - Best Individual: [0.0099, 0.1849, 0.0123, 0.0474, 0.3471, 0.2753, 0.0246, 0.0265, 0.0246, 0.0474], Max Fitness: 0.7175, Avg Fitness: 0.6076\n",
      "Generation 26 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6015\n",
      "Generation 27 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6285\n",
      "Generation 28 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6179\n",
      "Generation 29 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6228\n",
      "Generation 30 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6148\n",
      "Generation 31 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6209\n",
      "Generation 32 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6296\n",
      "Generation 33 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7025, Avg Fitness: 0.5956\n",
      "Generation 34 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6130\n",
      "Generation 35 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0391, 0.3466, 0.2749, 0.0343, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7200, Avg Fitness: 0.6251\n",
      "Generation 36 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6018\n",
      "Generation 37 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6290\n",
      "Generation 38 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6246\n",
      "Generation 39 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.5957\n",
      "Generation 40 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6079\n",
      "Generation 41 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6020\n",
      "Generation 42 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6043\n",
      "Generation 43 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6054\n",
      "Generation 44 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6024\n",
      "Generation 45 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6175\n",
      "Generation 46 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6079\n",
      "Generation 47 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.5930\n",
      "Generation 48 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6160\n",
      "Generation 49 - Best Individual: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473], Max Fitness: 0.7425, Avg Fitness: 0.6025\n"
     ]
    }
   ],
   "source": [
    "population_size = 150\n",
    "generations = 50\n",
    "mutation_prob = 0.3\n",
    "crossover_prob = 0.25\n",
    "selection_method = \"tournament\"\n",
    "tournament_size = 4\n",
    "num_games_per_individual = 100\n",
    "\n",
    "ga = CatanGA(\n",
    "    population_size=population_size, \n",
    "    generations=generations, \n",
    "    mutation_prob=mutation_prob, \n",
    "    crossover_prob=crossover_prob,\n",
    "    selection_method=selection_method,\n",
    "    tournament_size=tournament_size,\n",
    "    num_games_per_individual=num_games_per_individual\n",
    ")\n",
    "\n",
    "best_distribution = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best probability distribution and agent: [0.0099, 0.0246, 0.0123, 0.0428, 0.3466, 0.2749, 0.0306, 0.0264, 0.1846, 0.0473] <class 'Agents.CarlesZaidaAgent.CarlesZaidaAgent'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Best probability distribution and agent:\", [float(x) for x in best_distribution[0]], best_distribution[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.439433</td>\n",
       "      <td>0.7250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478250</td>\n",
       "      <td>0.6825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.507683</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.523900</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.531750</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.564467</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.568267</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.576267</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.563600</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.602867</td>\n",
       "      <td>0.7125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.591483</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.603800</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.602667</td>\n",
       "      <td>0.7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.606133</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.607217</td>\n",
       "      <td>0.7275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.615533</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.607583</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.604350</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.616733</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.612767</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.598083</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.609833</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.601633</td>\n",
       "      <td>0.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.605933</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.609117</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.607633</td>\n",
       "      <td>0.7175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.628550</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.617883</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.622767</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.614850</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.620867</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.629650</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.595583</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.612967</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.625050</td>\n",
       "      <td>0.7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.601833</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.628950</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.624567</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.595733</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.607867</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.602033</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.604333</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.605417</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.602350</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.617550</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.607950</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.592950</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.615967</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.602550</td>\n",
       "      <td>0.7425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gen       avg     max\n",
       "0     0  0.439433  0.7250\n",
       "1     1  0.478250  0.6825\n",
       "2     2  0.507683  0.6750\n",
       "3     3  0.523900  0.6750\n",
       "4     4  0.531750  0.6750\n",
       "5     5  0.564467  0.6750\n",
       "6     6  0.568267  0.6750\n",
       "7     7  0.576267  0.7000\n",
       "8     8  0.563600  0.7025\n",
       "9     9  0.602867  0.7125\n",
       "10   10  0.591483  0.7175\n",
       "11   11  0.603800  0.7275\n",
       "12   12  0.602667  0.7150\n",
       "13   13  0.606133  0.7200\n",
       "14   14  0.607217  0.7275\n",
       "15   15  0.615533  0.7175\n",
       "16   16  0.607583  0.6750\n",
       "17   17  0.604350  0.7000\n",
       "18   18  0.616733  0.7025\n",
       "19   19  0.612767  0.7175\n",
       "20   20  0.598083  0.7025\n",
       "21   21  0.609833  0.7000\n",
       "22   22  0.601633  0.7000\n",
       "23   23  0.605933  0.7175\n",
       "24   24  0.609117  0.7425\n",
       "25   25  0.607633  0.7175\n",
       "26   26  0.601450  0.7425\n",
       "27   27  0.628550  0.7425\n",
       "28   28  0.617883  0.7425\n",
       "29   29  0.622767  0.7425\n",
       "30   30  0.614850  0.7425\n",
       "31   31  0.620867  0.7425\n",
       "32   32  0.629650  0.7425\n",
       "33   33  0.595583  0.7025\n",
       "34   34  0.612967  0.7425\n",
       "35   35  0.625050  0.7200\n",
       "36   36  0.601833  0.7425\n",
       "37   37  0.628950  0.7425\n",
       "38   38  0.624567  0.7425\n",
       "39   39  0.595733  0.7425\n",
       "40   40  0.607867  0.7425\n",
       "41   41  0.602033  0.7425\n",
       "42   42  0.604333  0.7425\n",
       "43   43  0.605417  0.7425\n",
       "44   44  0.602350  0.7425\n",
       "45   45  0.617550  0.7425\n",
       "46   46  0.607950  0.7425\n",
       "47   47  0.592950  0.7425\n",
       "48   48  0.615967  0.7425\n",
       "49   49  0.602550  0.7425"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ga.logbook)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./res_trials/trial_annealing_crossover1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm_annealing import CatanGA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\valel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 - Best Individual: [0.1698, 0.0449, 0.0081, 0.0543, 0.0515, 0.0505, 0.1159, 0.2861, 0.1102, 0.1087], Max Fitness: 0.6150, Avg Fitness: 0.4450\n",
      "Generation 1 - Best Individual: [0.0012, 0.0421, 0.0251, 0.0035, 0.1422, 0.0711, 0.0268, 0.2425, 0.0322, 0.4132], Max Fitness: 0.6275, Avg Fitness: 0.4543\n",
      "Generation 2 - Best Individual: [0.0147, 0.0644, 0.0072, 0.0393, 0.2297, 0.072, 0.0225, 0.2889, 0.0146, 0.2468], Max Fitness: 0.6600, Avg Fitness: 0.4986\n",
      "Generation 3 - Best Individual: [0.0223, 0.2942, 0.0611, 0.1137, 0.2944, 0.1121, 0.033, 0.0058, 0.0317, 0.0317], Max Fitness: 0.6750, Avg Fitness: 0.5115\n",
      "Generation 4 - Best Individual: [0.0223, 0.2942, 0.0611, 0.1137, 0.2944, 0.1121, 0.033, 0.0058, 0.0317, 0.0317], Max Fitness: 0.6750, Avg Fitness: 0.5315\n",
      "Generation 5 - Best Individual: [0.0086, 0.0204, 0.0534, 0.0102, 0.0664, 0.062, 0.0534, 0.5503, 0.0102, 0.1651], Max Fitness: 0.6475, Avg Fitness: 0.5446\n",
      "Generation 6 - Best Individual: [0.0147, 0.0644, 0.0072, 0.0393, 0.2297, 0.072, 0.0225, 0.2888, 0.0146, 0.2468], Max Fitness: 0.6775, Avg Fitness: 0.5506\n",
      "Generation 7 - Best Individual: [0.0045, 0.0446, 0.0347, 0.0302, 0.1176, 0.0666, 0.0642, 0.3196, 0.0234, 0.2946], Max Fitness: 0.6575, Avg Fitness: 0.5236\n",
      "Generation 8 - Best Individual: [0.0083, 0.0394, 0.0487, 0.0394, 0.0864, 0.0638, 0.0638, 0.4601, 0.0135, 0.1766], Max Fitness: 0.6650, Avg Fitness: 0.5570\n",
      "Generation 9 - Best Individual: [0.0061, 0.0374, 0.04, 0.0843, 0.0937, 0.0613, 0.0613, 0.3787, 0.017, 0.2202], Max Fitness: 0.6850, Avg Fitness: 0.5574\n",
      "Generation 10 - Best Individual: [0.0057, 0.0351, 0.0399, 0.1041, 0.0399, 0.0639, 0.0639, 0.3871, 0.0183, 0.2421], Max Fitness: 0.6675, Avg Fitness: 0.5491\n",
      "Generation 11 - Best Individual: [0.0057, 0.0351, 0.0399, 0.1041, 0.0399, 0.0639, 0.0639, 0.3871, 0.0183, 0.2421], Max Fitness: 0.6675, Avg Fitness: 0.5459\n",
      "Generation 12 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5584\n",
      "Generation 13 - Best Individual: [0.0072, 0.0262, 0.0456, 0.037, 0.0777, 0.0607, 0.0606, 0.4669, 0.0141, 0.204], Max Fitness: 0.6625, Avg Fitness: 0.5709\n",
      "Generation 14 - Best Individual: [0.0077, 0.0293, 0.0512, 0.0273, 0.0273, 0.0293, 0.0678, 0.519, 0.0155, 0.2256], Max Fitness: 0.6775, Avg Fitness: 0.5752\n",
      "Generation 15 - Best Individual: [0.0069, 0.0216, 0.0452, 0.0771, 0.0709, 0.0581, 0.0598, 0.4642, 0.0122, 0.184], Max Fitness: 0.6550, Avg Fitness: 0.5747\n",
      "Generation 16 - Best Individual: [0.0057, 0.0329, 0.0399, 0.0551, 0.0938, 0.0622, 0.0619, 0.3926, 0.0177, 0.2382], Max Fitness: 0.6750, Avg Fitness: 0.5862\n",
      "Generation 17 - Best Individual: [0.0077, 0.0293, 0.0512, 0.0273, 0.0273, 0.0293, 0.0678, 0.519, 0.0155, 0.2256], Max Fitness: 0.6775, Avg Fitness: 0.5796\n",
      "Generation 18 - Best Individual: [0.0057, 0.0331, 0.0399, 0.0536, 0.0942, 0.0623, 0.062, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6450, Avg Fitness: 0.5762\n",
      "Generation 19 - Best Individual: [0.007, 0.0274, 0.0443, 0.0365, 0.0836, 0.0616, 0.0614, 0.4461, 0.0178, 0.2143], Max Fitness: 0.6625, Avg Fitness: 0.5808\n",
      "Generation 20 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5892\n",
      "Generation 21 - Best Individual: [0.007, 0.0274, 0.0443, 0.0365, 0.0836, 0.0616, 0.0614, 0.4461, 0.0178, 0.2143], Max Fitness: 0.6625, Avg Fitness: 0.5667\n",
      "Generation 22 - Best Individual: [0.0052, 0.0492, 0.0364, 0.0489, 0.0859, 0.0568, 0.0565, 0.3576, 0.0853, 0.2182], Max Fitness: 0.6500, Avg Fitness: 0.5793\n",
      "Generation 23 - Best Individual: [0.0052, 0.0859, 0.0364, 0.0489, 0.0859, 0.0569, 0.0566, 0.3571, 0.0489, 0.2182], Max Fitness: 0.6550, Avg Fitness: 0.5787\n",
      "Generation 24 - Best Individual: [0.0052, 0.0492, 0.0364, 0.0489, 0.0859, 0.0568, 0.0565, 0.3576, 0.0853, 0.2182], Max Fitness: 0.6600, Avg Fitness: 0.5761\n",
      "Generation 25 - Best Individual: [0.0044, 0.0734, 0.0311, 0.0418, 0.0734, 0.0486, 0.0483, 0.3058, 0.1866, 0.1866], Max Fitness: 0.6500, Avg Fitness: 0.5781\n",
      "Generation 26 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5696\n",
      "Generation 27 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5849\n",
      "Generation 28 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5861\n",
      "Generation 29 - Best Individual: [0.0054, 0.0444, 0.0375, 0.0503, 0.0884, 0.0584, 0.0582, 0.3678, 0.0651, 0.2245], Max Fitness: 0.6700, Avg Fitness: 0.5764\n",
      "Generation 30 - Best Individual: [0.0053, 0.0583, 0.0373, 0.0538, 0.0881, 0.0583, 0.0543, 0.3669, 0.0538, 0.2239], Max Fitness: 0.6750, Avg Fitness: 0.5893\n",
      "Generation 31 - Best Individual: [0.0053, 0.0452, 0.0373, 0.0501, 0.088, 0.0582, 0.0579, 0.3661, 0.0684, 0.2235], Max Fitness: 0.6625, Avg Fitness: 0.5886\n",
      "Generation 32 - Best Individual: [0.0057, 0.0331, 0.0399, 0.0536, 0.0942, 0.0623, 0.062, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6450, Avg Fitness: 0.5894\n",
      "Generation 33 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5808\n",
      "Generation 34 - Best Individual: [0.0057, 0.0331, 0.0399, 0.0536, 0.0942, 0.0623, 0.062, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6450, Avg Fitness: 0.5936\n",
      "Generation 35 - Best Individual: [0.0044, 0.0734, 0.0311, 0.0418, 0.0734, 0.0486, 0.0483, 0.3058, 0.1866, 0.1866], Max Fitness: 0.6500, Avg Fitness: 0.5829\n",
      "Generation 36 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5918\n",
      "Generation 37 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5846\n",
      "Generation 38 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5799\n",
      "Generation 39 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5813\n",
      "Generation 40 - Best Individual: [0.0062, 0.0358, 0.0431, 0.058, 0.0419, 0.0454, 0.067, 0.4245, 0.0192, 0.2589], Max Fitness: 0.6675, Avg Fitness: 0.5785\n",
      "Generation 41 - Best Individual: [0.0058, 0.0337, 0.0406, 0.0576, 0.0826, 0.0586, 0.06, 0.3994, 0.0181, 0.2436], Max Fitness: 0.6675, Avg Fitness: 0.5909\n",
      "Generation 42 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5752\n",
      "Generation 43 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5603\n",
      "Generation 44 - Best Individual: [0.0058, 0.0337, 0.0406, 0.0576, 0.0826, 0.0586, 0.06, 0.3994, 0.0181, 0.2436], Max Fitness: 0.6675, Avg Fitness: 0.5739\n",
      "Generation 45 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5702\n",
      "Generation 46 - Best Individual: [0.0062, 0.0361, 0.0435, 0.0607, 0.0361, 0.0435, 0.0654, 0.428, 0.0194, 0.2611], Max Fitness: 0.7025, Avg Fitness: 0.5847\n",
      "Generation 47 - Best Individual: [0.0044, 0.0726, 0.0312, 0.0421, 0.0726, 0.0483, 0.0482, 0.3066, 0.187, 0.187], Max Fitness: 0.6475, Avg Fitness: 0.5588\n",
      "Generation 48 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5827\n",
      "Generation 49 - Best Individual: [0.0057, 0.0331, 0.0399, 0.062, 0.0942, 0.0623, 0.0536, 0.3921, 0.0178, 0.2393], Max Fitness: 0.6925, Avg Fitness: 0.5922\n"
     ]
    }
   ],
   "source": [
    "population_size = 150\n",
    "generations = 50\n",
    "mutation_prob = 0.3\n",
    "crossover_prob = 0.5\n",
    "selection_method = \"tournament\"\n",
    "tournament_size = 4\n",
    "num_games_per_individual = 100\n",
    "\n",
    "ga = CatanGA(\n",
    "    population_size=population_size, \n",
    "    generations=generations, \n",
    "    mutation_prob=mutation_prob, \n",
    "    crossover_prob=crossover_prob,\n",
    "    selection_method=selection_method,\n",
    "    tournament_size=tournament_size,\n",
    "    num_games_per_individual=num_games_per_individual\n",
    ")\n",
    "\n",
    "best_distribution = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best probability distribution and agent: [0.0062, 0.0361, 0.0435, 0.0607, 0.0361, 0.0435, 0.0654, 0.428, 0.0194, 0.2611] <class 'Agents.PabloAleixAlexAgent.PabloAleixAlexAgent'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Best probability distribution and agent:\", [float(x) for x in best_distribution[0]], best_distribution[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.445050</td>\n",
       "      <td>0.6150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.454317</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.498633</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.511500</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.531467</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.544583</td>\n",
       "      <td>0.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.550617</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.6575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.556983</td>\n",
       "      <td>0.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.557367</td>\n",
       "      <td>0.6850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.549133</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.545867</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.570917</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.575250</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.574717</td>\n",
       "      <td>0.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.586183</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.579617</td>\n",
       "      <td>0.6775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.576233</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.580833</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.589233</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.566683</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.579300</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.6550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.576100</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.578067</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.569650</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.584867</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.586133</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.576383</td>\n",
       "      <td>0.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.589283</td>\n",
       "      <td>0.6750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.588650</td>\n",
       "      <td>0.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.589350</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.580850</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.593567</td>\n",
       "      <td>0.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.582917</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.591783</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.584633</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.579917</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.578550</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.590900</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.575217</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.560283</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.573867</td>\n",
       "      <td>0.6675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.570217</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.584683</td>\n",
       "      <td>0.7025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.558833</td>\n",
       "      <td>0.6475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.582717</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gen       avg     max\n",
       "0     0  0.445050  0.6150\n",
       "1     1  0.454317  0.6275\n",
       "2     2  0.498633  0.6600\n",
       "3     3  0.511500  0.6750\n",
       "4     4  0.531467  0.6750\n",
       "5     5  0.544583  0.6475\n",
       "6     6  0.550617  0.6775\n",
       "7     7  0.523600  0.6575\n",
       "8     8  0.556983  0.6650\n",
       "9     9  0.557367  0.6850\n",
       "10   10  0.549133  0.6675\n",
       "11   11  0.545867  0.6675\n",
       "12   12  0.558400  0.6925\n",
       "13   13  0.570917  0.6625\n",
       "14   14  0.575250  0.6775\n",
       "15   15  0.574717  0.6550\n",
       "16   16  0.586183  0.6750\n",
       "17   17  0.579617  0.6775\n",
       "18   18  0.576233  0.6450\n",
       "19   19  0.580833  0.6625\n",
       "20   20  0.589233  0.6925\n",
       "21   21  0.566683  0.6625\n",
       "22   22  0.579300  0.6500\n",
       "23   23  0.578717  0.6550\n",
       "24   24  0.576100  0.6600\n",
       "25   25  0.578067  0.6500\n",
       "26   26  0.569650  0.6925\n",
       "27   27  0.584867  0.6925\n",
       "28   28  0.586133  0.6925\n",
       "29   29  0.576383  0.6700\n",
       "30   30  0.589283  0.6750\n",
       "31   31  0.588650  0.6625\n",
       "32   32  0.589350  0.6450\n",
       "33   33  0.580850  0.6925\n",
       "34   34  0.593567  0.6450\n",
       "35   35  0.582917  0.6500\n",
       "36   36  0.591783  0.6925\n",
       "37   37  0.584633  0.6925\n",
       "38   38  0.579917  0.6925\n",
       "39   39  0.581300  0.6925\n",
       "40   40  0.578550  0.6675\n",
       "41   41  0.590900  0.6675\n",
       "42   42  0.575217  0.6925\n",
       "43   43  0.560283  0.6925\n",
       "44   44  0.573867  0.6675\n",
       "45   45  0.570217  0.6925\n",
       "46   46  0.584683  0.7025\n",
       "47   47  0.558833  0.6475\n",
       "48   48  0.582717  0.6925\n",
       "49   49  0.592233  0.6925"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ga.logbook)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./res_trials/trial_annealing_crossover2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm_annealing import CatanGA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\valel\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 - Best Individual: [0.0859, 0.0779, 0.0021, 0.0847, 0.0623, 0.0398, 0.408, 0.0553, 0.1725, 0.0113], Max Fitness: 0.6250, Avg Fitness: 0.4324\n",
      "Generation 1 - Best Individual: [0.0516, 0.1134, 0.045, 0.1099, 0.1574, 0.0567, 0.0909, 0.2101, 0.0516, 0.1134], Max Fitness: 0.6250, Avg Fitness: 0.4745\n",
      "Generation 2 - Best Individual: [0.0238, 0.0619, 0.0054, 0.0397, 0.0406, 0.4466, 0.1652, 0.0999, 0.0704, 0.0465], Max Fitness: 0.6400, Avg Fitness: 0.4894\n",
      "Generation 3 - Best Individual: [0.0238, 0.0619, 0.0054, 0.0397, 0.0406, 0.4466, 0.1652, 0.0999, 0.0704, 0.0465], Max Fitness: 0.5950, Avg Fitness: 0.4918\n",
      "Generation 4 - Best Individual: [0.0217, 0.0592, 0.039, 0.0248, 0.0592, 0.3638, 0.2325, 0.1286, 0.039, 0.0322], Max Fitness: 0.6525, Avg Fitness: 0.4875\n",
      "Generation 5 - Best Individual: [0.0296, 0.0396, 0.0782, 0.0514, 0.0946, 0.1189, 0.0955, 0.1436, 0.2583, 0.0903], Max Fitness: 0.6275, Avg Fitness: 0.5130\n",
      "Generation 6 - Best Individual: [0.0172, 0.0252, 0.0811, 0.0084, 0.0679, 0.2126, 0.2386, 0.1599, 0.1693, 0.0198], Max Fitness: 0.6975, Avg Fitness: 0.4953\n",
      "Generation 7 - Best Individual: [0.0262, 0.0524, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0767, 0.1581], Max Fitness: 0.6500, Avg Fitness: 0.5016\n",
      "Generation 8 - Best Individual: [0.0262, 0.0524, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0767, 0.1581], Max Fitness: 0.6500, Avg Fitness: 0.5007\n",
      "Generation 9 - Best Individual: [0.0172, 0.0252, 0.0811, 0.0084, 0.0679, 0.2126, 0.2386, 0.1599, 0.1693, 0.0198], Max Fitness: 0.6975, Avg Fitness: 0.5091\n",
      "Generation 10 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5093\n",
      "Generation 11 - Best Individual: [0.0257, 0.0461, 0.0651, 0.0417, 0.132, 0.0417, 0.2581, 0.132, 0.1428, 0.1148], Max Fitness: 0.6250, Avg Fitness: 0.5055\n",
      "Generation 12 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5353\n",
      "Generation 13 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5038\n",
      "Generation 14 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5321\n",
      "Generation 15 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6275, Avg Fitness: 0.5288\n",
      "Generation 16 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5430\n",
      "Generation 17 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6275, Avg Fitness: 0.5438\n",
      "Generation 18 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5650\n",
      "Generation 19 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5218\n",
      "Generation 20 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5299\n",
      "Generation 21 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5108\n",
      "Generation 22 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5180\n",
      "Generation 23 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5242\n",
      "Generation 24 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5504\n",
      "Generation 25 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5406\n",
      "Generation 26 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5399\n",
      "Generation 27 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5089\n",
      "Generation 28 - Best Individual: [0.0268, 0.0684, 0.0416, 0.0463, 0.0795, 0.17, 0.252, 0.0905, 0.0634, 0.1615], Max Fitness: 0.6350, Avg Fitness: 0.5098\n",
      "Generation 29 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5278\n",
      "Generation 30 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5103\n",
      "Generation 31 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5653\n",
      "Generation 32 - Best Individual: [0.0281, 0.0702, 0.0436, 0.0485, 0.1693, 0.0436, 0.2644, 0.0949, 0.0681, 0.1693], Max Fitness: 0.6325, Avg Fitness: 0.5133\n",
      "Generation 33 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5453\n",
      "Generation 34 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5210\n",
      "Generation 35 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5211\n",
      "Generation 36 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5370\n",
      "Generation 37 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5355\n",
      "Generation 38 - Best Individual: [0.0262, 0.0667, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0624, 0.1581], Max Fitness: 0.6725, Avg Fitness: 0.5223\n",
      "Generation 39 - Best Individual: [0.0262, 0.0667, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0624, 0.1581], Max Fitness: 0.6725, Avg Fitness: 0.5381\n",
      "Generation 40 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5353\n",
      "Generation 41 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5414\n",
      "Generation 42 - Best Individual: [0.0262, 0.0667, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0624, 0.1581], Max Fitness: 0.6725, Avg Fitness: 0.5320\n",
      "Generation 43 - Best Individual: [0.0262, 0.067, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0621, 0.1581], Max Fitness: 0.6600, Avg Fitness: 0.5357\n",
      "Generation 44 - Best Individual: [0.0262, 0.0655, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0636, 0.1581], Max Fitness: 0.6400, Avg Fitness: 0.5483\n",
      "Generation 45 - Best Individual: [0.0262, 0.0655, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0636, 0.1581], Max Fitness: 0.6400, Avg Fitness: 0.5575\n",
      "Generation 46 - Best Individual: [0.0281, 0.0715, 0.0436, 0.0485, 0.1693, 0.0436, 0.2645, 0.0949, 0.0667, 0.1693], Max Fitness: 0.7100, Avg Fitness: 0.5461\n",
      "Generation 47 - Best Individual: [0.0281, 0.0715, 0.0436, 0.0485, 0.1693, 0.0436, 0.2645, 0.0949, 0.0667, 0.1693], Max Fitness: 0.7100, Avg Fitness: 0.5375\n",
      "Generation 48 - Best Individual: [0.0262, 0.0655, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0636, 0.1581], Max Fitness: 0.6400, Avg Fitness: 0.5427\n",
      "Generation 49 - Best Individual: [0.0262, 0.0655, 0.0407, 0.0453, 0.041, 0.2241, 0.2469, 0.0886, 0.0636, 0.1581], Max Fitness: 0.6400, Avg Fitness: 0.5516\n"
     ]
    }
   ],
   "source": [
    "population_size = 150\n",
    "generations = 50\n",
    "mutation_prob = 0.3\n",
    "crossover_prob = 0.75\n",
    "selection_method = \"tournament\"\n",
    "tournament_size = 4\n",
    "num_games_per_individual = 100\n",
    "\n",
    "ga = CatanGA(\n",
    "    population_size=population_size, \n",
    "    generations=generations, \n",
    "    mutation_prob=mutation_prob, \n",
    "    crossover_prob=crossover_prob,\n",
    "    selection_method=selection_method,\n",
    "    tournament_size=tournament_size,\n",
    "    num_games_per_individual=num_games_per_individual\n",
    ")\n",
    "\n",
    "best_distribution = ga.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best probability distribution and agent: [0.0281, 0.0715, 0.0436, 0.0485, 0.1693, 0.0436, 0.2645, 0.0949, 0.0667, 0.1693] <class 'Agents.EdoAgent.EdoAgent'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Best probability distribution and agent:\", [float(x) for x in best_distribution[0]], best_distribution[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gen</th>\n",
       "      <th>avg</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432383</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.474483</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.489350</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.491783</td>\n",
       "      <td>0.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.487533</td>\n",
       "      <td>0.6525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.513050</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.495317</td>\n",
       "      <td>0.6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.501583</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.500733</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.509083</td>\n",
       "      <td>0.6975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.509333</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.505517</td>\n",
       "      <td>0.6250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.535283</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.503800</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.532100</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.528750</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.543817</td>\n",
       "      <td>0.6275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.565033</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.521833</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.529867</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.510750</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.518017</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.524183</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.550383</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.540633</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.539917</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.509767</td>\n",
       "      <td>0.6350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.527783</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>0.510300</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>0.565283</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>0.513267</td>\n",
       "      <td>0.6325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.545333</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.521033</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>0.521133</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>0.536983</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>0.535533</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>0.522283</td>\n",
       "      <td>0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>0.538050</td>\n",
       "      <td>0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>0.535317</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>0.541450</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>0.531950</td>\n",
       "      <td>0.6725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>0.535750</td>\n",
       "      <td>0.6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>44</td>\n",
       "      <td>0.548250</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>0.557550</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>0.546133</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>0.537450</td>\n",
       "      <td>0.7100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.542683</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>0.551650</td>\n",
       "      <td>0.6400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    gen       avg     max\n",
       "0     0  0.432383  0.6250\n",
       "1     1  0.474483  0.6250\n",
       "2     2  0.489350  0.6400\n",
       "3     3  0.491783  0.5950\n",
       "4     4  0.487533  0.6525\n",
       "5     5  0.513050  0.6275\n",
       "6     6  0.495317  0.6975\n",
       "7     7  0.501583  0.6500\n",
       "8     8  0.500733  0.6500\n",
       "9     9  0.509083  0.6975\n",
       "10   10  0.509333  0.6600\n",
       "11   11  0.505517  0.6250\n",
       "12   12  0.535283  0.6600\n",
       "13   13  0.503800  0.6600\n",
       "14   14  0.532100  0.6600\n",
       "15   15  0.528750  0.6275\n",
       "16   16  0.543017  0.6600\n",
       "17   17  0.543817  0.6275\n",
       "18   18  0.565033  0.6600\n",
       "19   19  0.521833  0.6600\n",
       "20   20  0.529867  0.6600\n",
       "21   21  0.510750  0.6600\n",
       "22   22  0.518017  0.6600\n",
       "23   23  0.524183  0.6600\n",
       "24   24  0.550383  0.6600\n",
       "25   25  0.540633  0.6600\n",
       "26   26  0.539917  0.6600\n",
       "27   27  0.508867  0.6600\n",
       "28   28  0.509767  0.6350\n",
       "29   29  0.527783  0.6600\n",
       "30   30  0.510300  0.6600\n",
       "31   31  0.565283  0.6600\n",
       "32   32  0.513267  0.6325\n",
       "33   33  0.545333  0.6600\n",
       "34   34  0.521033  0.6600\n",
       "35   35  0.521133  0.6600\n",
       "36   36  0.536983  0.6600\n",
       "37   37  0.535533  0.6600\n",
       "38   38  0.522283  0.6725\n",
       "39   39  0.538050  0.6725\n",
       "40   40  0.535317  0.6600\n",
       "41   41  0.541450  0.6600\n",
       "42   42  0.531950  0.6725\n",
       "43   43  0.535750  0.6600\n",
       "44   44  0.548250  0.6400\n",
       "45   45  0.557550  0.6400\n",
       "46   46  0.546133  0.7100\n",
       "47   47  0.537450  0.7100\n",
       "48   48  0.542683  0.6400\n",
       "49   49  0.551650  0.6400"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(ga.logbook)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./res_trials/trial_annealing_crossover3.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
